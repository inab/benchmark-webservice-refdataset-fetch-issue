// General configuration used in all profiles
manifest {
  description = 'QfO orthology benchmark service'
  nextflowVersion = '19.10.0'
}

// Profiles configure nextflow depending on the environment (local, integration, live, etc.)
profiles {

  docker {
    process {
      withLabel: py {
        container = "qfobenchmark/python:FAS"
      }
    }

    process {
      withLabel: darwin {
        container = "qfobenchmark/darwin:FAS"
      }
    }

    process {
      withLabel: fas {
        container = "qfobenchmark/fas_benchmark:FAS"
      }
    }

    docker.enabled = true

    // env.QFO_REFSET_PATH = "$params.refset"
    
  }
  singularity {
    process {
      withLabel: py {
        container = "qfobenchmark/python:FAS"
      }

      withLabel: darwin {
        container = "qfobenchmark/darwin:FAS"
      }

      withLabel: fas {
        container = "qfobenchmark/fas_benchmark:FAS"
      }
    }
    singularity.enabled = true
    singularity.autoMounts = true
  }



}

// default parameter values

params  {

  // submitted file
  input = "$baseDir/example/oma-groups.orthoxml.gz"

  // name of the tool used for the predicitions
  participant_id = "OMA Groups"

  // GO specific parameters
  go_evidences = "exp"

  //name or OEB permanent ID for the benchmarking community
  community_id = "QfO"

  // benchmarks to be performed
  challenges_ids = "GO EC VGNC SwissTrees TreeFam-A STD_Eukaryota STD_Fungi STD_Bacteria G_STD_Luca G_STD_Eukaryota G_STD_Vertebrata G_STD_Fungi G_STD2_Luca G_STD2_Fungi G_STD2_Eukaryota G_STD2_Vertebrata FAS"

  event_year = 2022

  // goldstandard results
  goldstandard_dir = "reference_data/${params.event_year}"

  // directory where assessment data of existing projects is found
  assess_dir = "reference_data/data"

  // directories where results will be written
  results_dir = "out"
  validation_result = "${params.results_dir}/participant_out"
  assessment_results = "${params.results_dir}/assessment_out/Assessment_datasets.json"
  outdir = "${params.results_dir}/results"
  statsdir = "${params.results_dir}/stats"
  data_model_export_dir = "${params.results_dir}/benchmarking_data_model_export/consolidated_results.json"
  otherdir = "${params.results_dir}/other"
  cpy_sqlite_db = true
  help = false
}


// By default output execution reports
def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
  enabled = true
  file = "${params.statsdir}/timeline_${trace_timestamp}.html"
}
report {
  enabled = true
  file = "${params.statsdir}/report_${trace_timestamp}.html"
}
trace {
  enabled = true
  file = "${params.statsdir}/trace_${trace_timestamp}.txt"
  overwrite = true
}
dag {
  enabled = true
  file = "${params.statsdir}/DAG_${trace_timestamp}.dot"
  overwrite = true
}

// here you can include cluster specific configs
// includeConfig 'conf/curnagl.config'
